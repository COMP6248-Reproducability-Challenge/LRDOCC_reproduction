{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "\n",
    "from urllib.request import urlopen\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "\n",
    "from tqdm.autonotebook import tqdm\n",
    "from itertools import chain\n",
    "\n",
    "from autoencoder import Encoder, Decoder\n",
    "from helper import K9_dataloader, K9_stratified_class_sample, K9_OCSVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain denoising representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_denoising_reps(train_loader, test_loader, dataset):\n",
    "    enc_dim    = 64\n",
    "    latent_dim = 75\n",
    "    epochs     = 10\n",
    "\n",
    "    if dataset == 'fMNIST':\n",
    "        image_dim = 784\n",
    "    else:\n",
    "        image_dim  = 3072\n",
    "\n",
    "    enc = Encoder(image_dim, enc_dim, latent_dim)\n",
    "    dec = Decoder(latent_dim, enc_dim, image_dim)\n",
    "    optimizer = optim.Adam(chain(enc.parameters(), dec.parameters()), lr=1e-3)\n",
    "\n",
    "    print('Training denoising autoencoder\\n------------------------------')\n",
    "    for epoch in range(epochs):\n",
    "        losses = []\n",
    "        trainloader = tqdm(train_loader)\n",
    "\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, _ = data\n",
    "\n",
    "            noisy_inputs = inputs\n",
    "            for idx, input in enumerate(noisy_inputs):\n",
    "                noisy_inputs[idx][torch.randint(input.shape[0],(int(input.shape[0] * 25 / 100),))] = 0\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            z = enc(noisy_inputs)\n",
    "            noisy_z = z\n",
    "            for idx, z_rep in enumerate(noisy_z):\n",
    "                noisy_z[idx][torch.randint(z_rep.shape[0],(int(z_rep.shape[0] * 25 / 100),))] = 1\n",
    "\n",
    "            outputs = dec(noisy_z)\n",
    "\n",
    "            loss = F.binary_cross_entropy(outputs, inputs, reduction='sum') / inputs.shape[0]\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # keep track of the loss and update the stats\n",
    "            losses.append(loss.item())\n",
    "            trainloader.set_postfix(loss=np.mean(losses), epoch=epoch)\n",
    "\n",
    "    train_set_X, train_set_y = [], []\n",
    "    test_set_X , test_set_y  = [], []\n",
    "\n",
    "    for input, target in (train_loader):\n",
    "        for x, y in zip(input, target):\n",
    "            train_set_X.append(enc(x).detach())\n",
    "            train_set_y.append(y)\n",
    "\n",
    "    for input, target in (test_loader):\n",
    "        for x, y in zip(input, target):\n",
    "            test_set_X.append(enc(x).detach())\n",
    "            test_set_y.append(y)\n",
    "\n",
    "    return train_set_X, train_set_y, test_set_X, test_set_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit OC-SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimal example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Download dataset\n",
    "train_loader, test_loader = K9_dataloader(dataset='CIFAR10', batch_size=256)\n",
    "\n",
    "# Obtain representations\n",
    "tr_X, tr_y, ts_X, ts_y = get_denoising_reps(train_loader, test_loader, 'CIFAR10')\n",
    "\n",
    "# Prepare data to fit OC-SVM\n",
    "X_train, y_train = K9_stratified_class_sample(torch.stack(tr_X), np.array(tr_y))\n",
    "X_test, y_test   = torch.stack(ts_X),  np.array(ts_y)\n",
    "\n",
    "# Fit OC-SVM\n",
    "oc_svm = K9_OCSVM(X_train, y_train, X_test, y_test, kernel_type='rbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
